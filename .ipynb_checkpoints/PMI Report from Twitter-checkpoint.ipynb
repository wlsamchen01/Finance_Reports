{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "A script to download all of a user's tweets into a csv - https://gist.github.com/yanofsky/5436496\n",
    "Tweepy user-methods - http://docs.tweepy.org/en/latest/api.html#user-methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# screen name of the user to download tweets from\n",
    "#screen_name = \"LiveSquawk\"\n",
    "\n",
    "screen_name = 'YTradingAdvisor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import os\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1336500902384054271\n",
      "...391 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# read twitter consumer key and consumer secret from one folder up\n",
    "# storing authentication keys in a separate folder for security \n",
    "os.chdir('..')\n",
    "base_dir = os.getcwd()\n",
    "consumer_key = open(base_dir + '\\\\consumer_key.txt', 'r').read()\n",
    "consumer_secret = open(base_dir + '\\\\consumer_secret.txt', 'r').read()\n",
    "\n",
    "# authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "# Twitter only allows access to a user's most recent 3240 tweets with this\n",
    "# method as of 3 Jan 2021\n",
    "def get_all_tweets(screen_name):\n",
    "    # initialise a list to store all tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    # make initial request for the most recent tweets. 200 is max limit.\n",
    "    # excluding retweets and replies\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name\n",
    "                                  ,count = 200\n",
    "                                  ,exclude_replies = True\n",
    "                                  ,include_rts = False)\n",
    "    \n",
    "    # add new tweets to alltweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    # get the id of the oldest tweet so far. Get 1 less\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    # keep grabbing tweets until there are no tweets to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "        \n",
    "        # all subsequent requests use the max_id to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name\n",
    "                                      ,count = 200\n",
    "                                      ,max_id = oldest\n",
    "                                      ,exclude_replies = True\n",
    "                                      ,include_rts = False)\n",
    "        \n",
    "        # add the tweets to alltweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        # get the id of the oldest tweet so far. Get 1 less\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "        \n",
    "        return alltweets\n",
    "\n",
    "all_tweets = get_all_tweets(\"YTradingAdvisor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Latest PMI tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "#for tweet in PMI_tweets:\n",
    "#    print(tweet.created_at, tweet.text, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMI Report by Country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of tweets with 'PMI' in the tweet text\n",
    "PMI_tweets = []\n",
    "for tweet in all_tweets:\n",
    "    if ('PMI' in tweet.text):\n",
    "        PMI_tweets.append(tweet)\n",
    "\n",
    "# create a dictionary with 'PMI' tweets stored by country\n",
    "country_list = ['China'\n",
    "                ,'Germany'\n",
    "                ,'US'\n",
    "                ,'UK']\n",
    "\n",
    "PMI_tweets_by_country = {}\n",
    "\n",
    "for country in country_list:\n",
    "    country_tweets = []\n",
    "    for tweet in PMI_tweets:\n",
    "        if country in tweet.text:\n",
    "            country_tweets.append(tweet)\n",
    "    PMI_tweets_by_country[country] = country_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Output as a Word Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()\n",
    "\n",
    "document.add_heading('Macro Economic Report - PMI', 0)\n",
    "\n",
    "document.add_heading('PMI', 1)\n",
    "\n",
    "for country in PMI_tweets_by_country:\n",
    "    document.add_heading(f'------------- {country} PMI --------------------- :', 2)\n",
    "    for tweet in PMI_tweets_by_country[country]:\n",
    "        document.add_paragraph(str(tweet.created_at) + str(tweet.text))\n",
    "\n",
    "#save file\n",
    "os.chdir('Finance Reports')\n",
    "document.save('Macro Economic Report - PMI.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
